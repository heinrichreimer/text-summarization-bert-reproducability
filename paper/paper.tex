\documentclass[english,sigconf,nonacm,natbib=false,balance=false,screen,review]{acmart}
\usepackage{babel}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage[style=alphabetic]{biblatex}
\addbibresource{paper.bib}

\title{Reproducing Text Summarization with Pretrained Encoders}
\author{Jan Heinrich Reimer}
\orcid{0000-0003-1992-8696}
\affiliation{
    \institution{Martin Luther University Halle-Wittenberg}
    % \department{Institute for Computer Science}
    \streetaddress{Von-Seckendorff-Platz~1}
    \postcode{06108}
    \city{Halle (Saale)}
    % \state{Sachsen-Anhalt}
    \country{Germany}
}
\email{jan.reimer@student.uni-halle.de}

\begin{document}

\begin{abstract}
    Pretrained encoders like BERT are commonly used for summarizing text. \citeauthor{DBLP:conf/emnlp/LiuL19} introduce models for extractive and abstractive summarization based on the pretrained BERT model~\cite{DBLP:conf/emnlp/LiuL19}.
    We reproduce their models and experiments on the \href{https://fluxml.ai/}{Flux} framework.
\end{abstract}

\maketitle

\input{sections/01-introduction.tex}
\input{sections/02-related-work.tex}
\input{sections/03-fine-tuning-summarization-encoder.tex}
\input{sections/04-experimental-evaluation.tex}
\input{sections/05-conclusion-future-work.tex}

\printbibliography

\end{document}